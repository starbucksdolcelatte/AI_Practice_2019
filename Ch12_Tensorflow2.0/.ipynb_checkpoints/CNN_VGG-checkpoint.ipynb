{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import keras\n",
    "from tensorflow.compat.v1.keras.utils import to_categorical, get_source_inputs\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "#from keras import backend as K\n",
    "from keras import applications\n",
    "from tensorflow.compat.v1.keras.layers import Conv2D, GlobalAveragePooling2D, Flatten, Dense, Activation, MaxPooling2D\n",
    "from tensorflow.compat.v1.keras.layers import Dropout, Input, BatchNormalization\n",
    "from tensorflow.compat.v1.keras import Model\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터를 불러옵니다.\n",
    "mnist = np.load('mnist.npz')\n",
    "\n",
    "# TODO : Train Data와 Test Data로 분리해보세요.\n",
    "# 데이터의 개수는 Train 100개, Test 20개로 분리합니다.\n",
    "X_train, X_test, y_train, y_test = mnist['x_train'][:100], mnist['x_test'][:20], mnist['y_train'][:100], mnist['y_test'][:20]\n",
    "\n",
    "# TODO : Train Data의 Pixel 값을 0 ~ 255에서 0 ~ 1 사이의 Float 데이터로 바꿔보세요.\n",
    "X_train = X_train.astype(np.float)/255.\n",
    "X_test = X_test.astype(np.float)/255.\n",
    "\n",
    "# TODO : (num of data, 28, 28) 형태의 데이터를 (num of data, 28, 28, 1)로 만들어보세요. \n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing image argumentation...\n",
      "\n",
      "Image argumentation DONE...\n",
      "\n",
      "Doing Concatenate...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Data Augmenation을 위한 메서드입니다.\n",
    "def data_augmentation(image, label):\n",
    "    rotate_img = []\n",
    "    rotate_label = []\n",
    "    flip_img = []\n",
    "    flip_label = []\n",
    "    \n",
    "    print('Doing image argumentation...\\n')\n",
    "    for x, y in zip(image, label):\n",
    "        # TODO : 입력 영상을 Rotate 해보세요. 단 Rotate 각도는 Random으로 설정해주세요.\n",
    "        rotate_img.append(tf.image.rot90(x,int(np.random.randint(4,size=1))))\n",
    "        rotate_label.append(y)\n",
    "        \n",
    "        # TODO : 입력 영상을 좌우반전해보세요.\n",
    "        flip_img.append(tf.image.random_flip_left_right(x,int(np.random.randint(4,size=1))))\n",
    "        flip_label.append(y)\n",
    "        \n",
    "    aug_img = np.array(rotate_img + flip_img)\n",
    "    aug_label = np.array(rotate_label + flip_label)\n",
    "    print('Image argumentation DONE...\\n')\n",
    "    \n",
    "    return aug_img, aug_label\n",
    "    \n",
    "# TODO : Augmenation을 거친 데이터를 저장해주세요.\n",
    "aug_X_train, aug_y_train = data_augmentation(X_train, y_train)\n",
    "\n",
    "print('Doing Concatenate...\\n')\n",
    "X_train = np.concatenate((X_train,aug_X_train))\n",
    "y_train = np.concatenate((y_train,aug_y_train))\n",
    "\n",
    "# TODO : 0 ~ 9값을 가진 Data Label을 One Hot encoding 해주세요\n",
    "y_train = to_categorical(y_train, 10)    \n",
    "y_test = to_categorical(y_test, 10)    \n",
    "\n",
    "# TODO : CNN 모델을 만들어보세요.\n",
    "def CNN():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME', \n",
    "                                  input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer= keras.regularizers.l2(0.002)))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(units, dropout=0.2, activation='relu', block=1, layer=1):\n",
    "\n",
    "    def layer_wrapper(inp):\n",
    "        x = Conv2D(units, (3, 3), padding='same', name='block{}_conv{}'.format(block, layer))(inp)\n",
    "        x = BatchNormalization(name='block{}_bn{}'.format(block, layer))(x)\n",
    "        x = Activation(activation, name='block{}_act{}'.format(block, layer))(x)\n",
    "        x = Dropout(dropout, name='block{}_dropout{}'.format(block, layer))(x)\n",
    "        return x\n",
    "\n",
    "    return layer_wrapper\n",
    "\n",
    "def dense_block(units, dropout=0.2, activation='relu', name='fc1'):\n",
    "\n",
    "    def layer_wrapper(inp):\n",
    "        x = Dense(units, name=name)(inp)\n",
    "        x = BatchNormalization(name='{}_bn'.format(name))(x)\n",
    "        x = Activation(activation, name='{}_act'.format(name))(x)\n",
    "        x = Dropout(dropout, name='{}_dropout'.format(name))(x)\n",
    "        return x\n",
    "\n",
    "    return layer_wrapper\n",
    "        \n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#base_model = VGG16(weights='imagenet')\n",
    "\n",
    "def VGG16_BN(input_tensor=None, input_shape=None, classes=10, conv_dropout=0.1, dropout=0.3, activation='relu'):\n",
    "    \"\"\"Instantiates the VGG16 architecture with Batch Normalization\n",
    "    # Arguments\n",
    "        input_tensor: Keras tensor (i.e. output of `layers.Input()`) to use as image input for the model.\n",
    "        input_shape: shape tuple\n",
    "        classes: optional number of classes to classify images\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    \"\"\"\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = conv_block(32, dropout=conv_dropout, activation=activation, block=1, layer=1)(img_input)\n",
    "    x = conv_block(32, dropout=conv_dropout, activation=activation, block=1, layer=2)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(1, 1), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = conv_block(64, dropout=conv_dropout, activation=activation, block=2, layer=1)(x)\n",
    "    x = conv_block(64, dropout=conv_dropout, activation=activation, block=2, layer=2)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(1, 1), name='block2_pool')(x)\n",
    "    \n",
    "    # Block 3\n",
    "    x = conv_block(128, dropout=conv_dropout, activation=activation, block=3, layer=1)(x)\n",
    "    x = conv_block(128, dropout=conv_dropout, activation=activation, block=3, layer=2)(x)\n",
    "    x = conv_block(128, dropout=conv_dropout, activation=activation, block=3, layer=3)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(1, 1), name='block3_pool')(x)\n",
    "    '''\n",
    "    # Block 4\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=4, layer=1)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=4, layer=2)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=4, layer=3)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    \n",
    "    # Block 5\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=5, layer=1)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=5, layer=2)(x)\n",
    "    x = conv_block(256, dropout=conv_dropout, activation=activation, block=5, layer=3)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    '''\n",
    "\n",
    "    # Flatten\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # FC Layers\n",
    "    x = dense_block(128, dropout=dropout, activation=activation, name='fc1')(x)\n",
    "    x = dense_block(64, dropout=dropout, activation=activation, name='fc2')(x)\n",
    "    \n",
    "    # Classification block    \n",
    "    x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
    "    inputs = get_source_inputs(input_tensor) if input_tensor is not None else img_input\n",
    "\n",
    "    # Create model.\n",
    "    return Model(inputs, x, name='vgg16_bn')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16_bn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "block1_bn1 (BatchNormalizati (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "block1_act1 (Activation)     (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "block1_dropout1 (Dropout)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block1_bn2 (BatchNormalizati (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "block1_act2 (Activation)     (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "block1_dropout2 (Dropout)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 27, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "block2_bn1 (BatchNormalizati (None, 27, 27, 64)        256       \n",
      "_________________________________________________________________\n",
      "block2_act1 (Activation)     (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_dropout1 (Dropout)    (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 27, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block2_bn2 (BatchNormalizati (None, 27, 27, 64)        256       \n",
      "_________________________________________________________________\n",
      "block2_act2 (Activation)     (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_dropout2 (Dropout)    (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 26, 26, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block3_bn1 (BatchNormalizati (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "block3_act1 (Activation)     (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_dropout1 (Dropout)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 26, 26, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block3_bn2 (BatchNormalizati (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "block3_act2 (Activation)     (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_dropout2 (Dropout)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 26, 26, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block3_bn3 (BatchNormalizati (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "block3_act3 (Activation)     (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_dropout3 (Dropout)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_19  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "fc1_bn (BatchNormalization)  (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "fc1_act (Activation)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc1_dropout (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "fc2_bn (BatchNormalization)  (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "fc2_act (Activation)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc2_dropout (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 471,658\n",
      "Trainable params: 469,994\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "Train on 300 samples, validate on 20 samples\n",
      "Epoch 1/16\n",
      "300/300 - 53s - loss: 0.1019 - accuracy: 0.1100 - val_loss: 0.0900 - val_accuracy: 0.1500\n",
      "Epoch 2/16\n",
      "300/300 - 41s - loss: 0.0874 - accuracy: 0.2233 - val_loss: 0.0899 - val_accuracy: 0.1500\n",
      "Epoch 3/16\n"
     ]
    }
   ],
   "source": [
    "# 모델이 어떻게 생겼는지 확인해보세요..\n",
    "#model = CNN()\n",
    "model = VGG16_BN(input_shape=(28, 28, 1), classes=10, conv_dropout=0.2, \n",
    "                 dropout=0.3, activation='relu')\n",
    "model.summary()\n",
    "\n",
    "# TODO : 모델을 학습할 방법과 Error 계산 방법, 평가 방법을 설정해보세요.\n",
    "\n",
    "# 모델을 학습할 방법과 Error 계산 방법, 평가 방법을 설정합니다.\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "# 모델을 학습시켜줍니다.\n",
    "# verbose의 값에 따라 출력 형태를 바꿀 수 있습니다.\n",
    "# 0 : silent, 1 : progress bar, 2 : one line per epoch\n",
    "history = model.fit(X_train, y_train, epochs = 16, batch_size = 128, \n",
    "                    validation_data = (X_test, y_test), verbose = 1)\n",
    "\n",
    "# 테스트 데이터로 모델을 검증합니다.\n",
    "loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# 결과를 보고 분석해보세요.\n",
    "print('Test Loss : {:.4f} | Test Accuracy : {}'.format(loss, np.round(test_acc,3)))\n",
    "#print('Test Data로 예측한 클래스 : ',model.predict_classes(X_tt))\n",
    "#print('Test Data의 실제 클래스   : ',[np.argmax(i) for i in y_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
